##### 音视频的应用

1. 实时互动直播  
2. 娱乐直播 
3. 音视频特效
4. 音视编辑

##### 音视频直播架构

1. 泛娱乐化直播

   > 花椒映客斗鱼 
   >
   
1. 实时互动直播

   > 推流不一样rtp底层udp  webrtc  音视频会议、教育直播等，像Zoom、声网。特点是多人多视频实时互动，可以与固话进行互联，对延时要求较高，一般不超过400ms。相对于泛娱乐化直播，实时互动直播技术门槛更高。

目前，大多数用泛娱乐化直播，需要实时互动时用webRTC。

## 音频基础

##### 音频处理流程

1. 直播客户端的处理流程

​     音视频采集 -> 音视频编码（有损编码（去掉了哪些数据）、无损编码）-> 传输-> 音视频解码->音视频渲染

2. 音频数据的流转

​      PCM->aac/mp3 (压缩编码）->  mp4/flv (包装成多媒体文件)

##### 基础概念

比特率：表示经过编码（压缩）后的音频数据每秒钟需要用多少个比特来表示，单位常为kbps。

响度和强度：声音的主观属性响度表示的是一个声音听来有多响的程度。响度主要随声音的强度而变化，但也受频率的影响。总的说，中频纯音听来比低频和高频纯音响一些。

采样和采样率：采样是把连续的时间信号，变成离散的数字信号。采样率是指每秒钟采集多少个样本。

##### PCM与WAV

音频原始数据格式

1. pcm（纯原始数据）
2. WAV （原始数据pcm，就是在pcm上套了一个头）

量化的基本概念

1. 采样大小：一个采样用多是奥bit存放、常用16bit
2. 采样率：采样频率8K,16k、32k、44.1k、48K
3. 声道数：单声道、双声道、多声道

码率计算

采样率 * 采样大小 * 声道数

例如：采样率为44.1KHz,采样大小为16bit，双声道的pcm编码的WAV文件，它的码率为44.1K * 16 * 2 = 1411.2Kb/s

一般10m网络，下行速度10M,上行2M


![image-20210414091226530](image-20210414091226530.png)

#### 音频采集

##### 采集音频的方式

1. 不同平台不同层次的API，掌握难度大。
2. FFmpeg 采集音频，FFmpge已经把各平台封装好了
   1. 通过命令方式
      1. ffmpeg -f avfoundation(平台API) -i :0（不同平台不一样） out.wav
   2. 通过API方式

#### 音频编码

##### 音频压缩

压缩最小与压缩最快之间的平衡

1. 消除冗余信息（去除人听觉范围外信息以及掩蔽掉的音频信号，去除后无法还原，叫有损压缩）
2. 无损压缩（剔除掉冗余信息后，再进行无损压缩，让数据更小，zip、7z）

#####  音频冗余信息

音频压缩技术是在保证信号在听觉方面不产生失真的前提下，对音频数据信号进行尽可能大的压缩。

信号的遮蔽分为

1. 频域遮蔽
2. 时域遮蔽

![image-20210414094659732](image-20210414094659732.png)

![image-20210414094817427](image-20210414094817427.png)

##### 无损编码

###### 熵编码

哈夫曼编码、算术编码、香农编码

##### 音频编码过程

![image-20210414095320513](image-20210414095320513.png)**

#### 常见的音频编码器

##### 常见的音频编码器

OPUS（延迟小、压缩率高，webRTC默认使用，实时直播）、AAC（应用最广，直播系统）、Ogg（收费）、Speex、iLBC、AMR、G.711等

**结论**：OPUS > AAC > Ogg

##### 音频编码质量比较

![image-20210414100124374](image-20210414100124374.png)

##### 音频编码码率

![image-20210414100331388](image-20210414100331388.png)

#### AAC介绍

目的取代MP3格式

#### FFmpeg生成AAC

#### 协议介绍 [jianshu.com/p/32417d8ee5b6]()

### RTMP协议

苹果 HLS; tcp效率太低，未来趋势是udp。

##### 基本概念

![image-20210414133657113](image-20210414133657113.png)

RTMP创建流的的基本流程

1. socket建立TCP连接
2. rtmp握手
3. 建立rtmp连接
4. 创建rtmp流

![image-20210414134917205](image-20210414134917205.png)

### FLV协议

### 音视频直播架构

直播产品的种类

1. 泛娱乐化直播  花椒、映客、斗鱼
2. 实时互动直播  推流使用RTP底层UDP，流媒体服务器webRPC；音视频会议、教育直播等

## 视频基础

##### 编码格式

目的是为了压缩视频，H264 , VP8， AVS, RMVB，WMV，QuickTime（mov）等。

##### 封装格式

封装是按照一定的规则把编码后的视频+音频封装起来，提供容器，便于播放、同步和存储等。mp4、avi、flv等

##### 传输协议

RTSP、RTMP、HLS、HTTP-FLV

![image-20220218100136379](image-20220218100136379.png)

摄像头录制--->预处理（A/D转换）--->预处理（YUV转换等）--->压缩编码--->数据封装及传输--->解码--->图像格式变换 ---> 播放 

![image-20220420153428493](image-20220420153428493.png)

##### 图像

图像，是由很多“带有颜色的点”组成的。这个点，就是**“像素点”**。

像素点的英文叫Pixel（缩写为PX）。这个单词是由 Picture(图像) 和 Element（元素）这两个单词的字母所组成的。像素是图像显示的基本单位。我们通常说一幅图片的大小，例如是1920×1080，就是长度为1920个像素点，宽度为1080个像素点。乘积是2,073,600，也就是说，这个图片是两百万像素的。1920×1080，这个也被称为这幅图片的分辨率。

![image-20210420140403631](image-20210420140403631.png)

##### 人类视觉系统HVS

**HVS的构成：**

- 眼睛
- 神经
- 大脑

**HVS特点：**

- 对高频信息不敏感
- 对高对比度更敏感
- 对亮度信息比色度信息更敏感
- 对运动的信息更敏感

##### 针对HVS的特点，数字视频系统的设计应该考虑哪些因素？

- 丢弃高频信息，只编码低频信息
- 提高边缘信息的主观质量
- 降低色度的解析度
- 对感兴趣区域（Region of Interesting，ROI）进行特殊处理

##### 色彩

三原色：RGB，R、G、B 也被称为 **“基色分量”**。它们的取值，分别从 0 到 255，一共 256 个等级（256 是 2 的 8 次方）。

所以，任何颜色，都可以用 R、G、B 三个值的组合表示。一共能表示256×256×256=16 777 216简称16万色。每色有 8bit，这种方式表达出来的颜色，也被称为 **24 位色（**占用 24bit**）**。  已经超出人眼可见范围，又叫**真色彩**。

##### RGB的色彩问题

RGB与BGR

BMP使用的是BGR格式，需要进行转换

##### 图像与屏幕的关系

图像是数据，屏幕是显示设备， 图像数据经过驱动程序让屏幕显示图像

##### 屏幕指标

PPI (pixels per inch)  每英寸像素数。也就是，手机（或显示器）屏幕上每英寸面积，到底能放下多少个“像素点”。PPI越高也就显示的越细腻

DPI （Dots pen inch）每英寸的点数

PPI > 300  视网膜级别

##### 码流**（码率）**的计算

[码率是什么？比特率是干嘛的？帧速率是啥？分辨率又是什么？ - 知乎](https://zhuanlan.zhihu.com/p/75804693)

[直播不卡顿-上行带宽，码率如何换算？ - 掘金](https://juejin.cn/post/6960691749702336519)

码流(Data Rate)是指视频文件在单位时间内使用的数据流量，就是取样率,一般我们用的单位是kb/s或者Mb/s。一般来说同样分辨率下，视频文件的码流越大，压缩比就越小，画面质量就越高。码流越大，说明单位时间内取样率越大，数据流，精度就越高，处理出来的文件就越接近原始文件，图像质量越好，画质越清晰，要求播放设备的解码能力也越高。

##### 分辨率

分辨率 =  x轴的像素个数 * Y轴的像素个数

常见的宽高比 16:9  / 4:3    不是这俩比，要转换再渲染

360P/720P/1K/2K  都是16:9 

##### 帧率

视频每秒钟包括的画面数量（FPS，Frame per second）

每秒钟采集/ 播放图像的个数

动画的帧率是25帧/s，常见的15帧/s、30帧/s、 60帧/s

平滑度越高帧率越高，清晰度越高分辨率越高。85帧以上人眼识别不出来。

数字视频可以理解为自然场景空间和时间的数字采样表示。

空间采样的主要技术指标为：解析度（Resolution）（是否和分辨率为同一个概念）

时间采样的主要技术指标为：帧率（帧/秒）

##### 未编码视频的RGB码流

RGB码流 = 分辨率（宽 * 高） * 3（Byte）* 帧率

例如： 1280 * 720 * 3 * 25 约是69M，一般说按位， 再乘以8 

##### 主要压缩了什么东西？

原始视频压缩的目的是去除冗余信息，可以去除的冗余包括：

- 空间冗余：图像相邻像素之间有较强的相关性，根据局部相关性，同一张图像中临近的采样点之间往往存在着空间连续性，即颜色相同或相近；
- 时间冗余：视频序列的相邻图像之间内容相似，连续的画面之间存在着空间的连续性，即相邻图像之间变化的内容不是很多。
- 编码冗余：不同像素值出现的概率不同
- 视觉冗余：人的视觉系统对某些细节不敏感
- 知识冗余：规律性的结构可由先验知识和背景知识得到

##### 数据压缩是怎么分类的？

- **无损压缩（Lossless）：**压缩前、解压缩后图像完全一致X=X'，压缩比低(2:1~3:1)。典型格式例如：Winzip，JPEG-LS。
- **有损压缩（Lossy）：**压缩前解压缩后图像不一致X≠X'，压缩比高(10:1~20:1)，利用人的视觉系统的特性。典型格式例如：MPEG-2，H.264/AVC，AVS。

##### 编解码关键技术

- 预测：通过帧内预测和帧间预测降低视频图像的空间冗余和时间冗余。
- 变换：通过从时域到频域的变换，去除相邻数据之间的相关性，即去除时间冗余。
- 量化：通过用更粗糙的数据表示精细的数据来降低编码的数据量，或者通过去除人眼不敏感的信息来降低编码数据量。去掉视觉冗余，有损压缩
- 扫描：将二维变换量化数据重新组织成一维的数据序列。
- 熵编码：根据待编码数据的概率特性减少编码冗余。

```mermaid
graph LR
  帧内预测-->|去除空间冗余|变换
  变换-->|去除时间冗余|量化
  量化-->|去除视觉冗余有损压缩|熵编码-->|去除编码冗余|码流
```


![image-20210421112221273](image-20210421112221273.png)

##### 编码

终极目的压缩。

##### 图像的显示

图像大小 =  显示区域的大小     正好显示

图像大小 <   显示区域的大小    拉伸/留白

图像大小 >   显示区域的大小    缩小/截断

##### YUV色彩空间

Y表示明亮度，UV 描述影像色彩及饱和度，人眼对亮度敏感，对色度不敏感，因此减少部分UV的数据量，人眼却无法感知出来，这样可以通过压缩UV的分辨率，在不影响观感的前提下，减小视频的体积。

- **Y**：亮度，就是灰度值。除了表示亮度信号外，还含有较多的绿色通道量；
- **U**：蓝色通道与亮度的差值；
- **V**：红色通道与亮度的差值。

主要的采样格式有YUV4:2:0（最标准、应用最广，1/2压缩率）、YUV4:2:2和YUV4:4:4

##### RGB与YUV的关系

RGB用于屏幕图像的显示，YUV用于采集和编码。互相转换，计算公式：

```
Y = 0.299R ＋ 0.587G ＋ 0.114B
U = －0.147R － 0.289G ＋ 0.436B
V = 0.615R － 0.515G － 0.100B
——————————————————
R = Y ＋ 1.14V
G = Y － 0.39U － 0.58V
B = Y ＋ 2.03U
```

#### H.264标准的关键技术

##### 1. 帧内预测编码


帧内编码用来缩减图像的空间冗余。为了提高H.264帧内编码的效率，在给定帧中充分利用相邻宏块的空间相关性，相邻的宏块通常含有相似的属性。因此，在对一给定宏块编码时，首先可以根据周围的宏块预测（典型的是根据左上角的宏块，因为此宏块已经被编码处理），然后对预测值与实际值的差值进行编码，这样，相对于直接对该帧编码而言，可以大大减小码率。

##### 2.帧间预测编码


帧间预测编码利用连续帧中的时间冗余来进行运动估计和补偿。H.264的运动补偿支持以往的视频编码标准中的大部分关键特性，而且灵活地添加了更多的功能，除了支持P帧、B帧外，H.264还支持一种新的流间传送帧——SP帧，如图3所示。码流中包含SP帧后，能在有类似内容但有不同码率的码流之间快速切换，同时支持随机接入和快速回放模式。

##### 3.整数变换   


在变换方面，H.264使用了基于4×4像素块的类似于DCT的变换，但使用的是以整数为基础的空间变换，不存在反变换，因为取舍而存在误差的问题，变换矩阵如图5所示。与浮点运算相比，整数DCT变换会引起一些额外的误差，但因为DCT变换后的量化也存在量化误差，与之相比，整数DCT变换引起的量化误差影响并不大。此外，整数DCT变换还具有减少运算量和复杂度，有利于向定点DSP移植的优点。

##### 4.量化

 H.264中可选32种不同的量化步长，这与H.263中有31个量化步长很相似，但是在H.264中，步长是以12.5%的复合率递进的，而不是一个固定常数。

在H.264中，变换系数的读出方式也有两种：之字形（Zigzag）扫描和双扫描，如图6所示。大多数情况下使用简单的之字形扫描；双扫描仅用于使用较小量化级的块内，有助于提高编码效率。

##### 5熵编码

视频编码处理的最后一步就是熵编码，在H.264中采用了两种不同的熵编码方法：通用可变长编码（UVLC）和基于文本的自适应二进制算术编码（CABAC）。

在H.263等标准中，根据要编码的数据类型如变换系数、运动矢量等，采用不同的VLC码表。H.264中的UVLC码表提供了一个简单的方法，不管符号表述什么类型的数据，都使用统一变字长编码表。其优点是简单；缺点是单一的码表是从概率统计分布模型得出的，没有考虑编码符号间的相关性，在中高码率时效果不是很好。

因此，H.264中还提供了可选的CABAC方法。算术编码使编码和解码两边都能使用所有句法元素（变换系数、运动矢量）的概率模型。为了提高算术编码的效率，通过内容建模的过程，使基本概率模型能适应随视频帧而改变的统计特性。内容建模提供了编码符号的条件概率估计，利用合适的内容模型，存在于符号间的相关性可以通过选择目前要编码符号邻近的已编码符号的相应概率模型来去除，不同的句法元素通常保持不同的模型

##### H264压缩比



##### 码流参考值

[Site Unreachable](https://docs.agora.io/cn)

##### GOP

GOP是一个编码视频流中的一组连续的画面。每一个编码的视频流都由连续的GOP组成。压缩的视频流中GOP相对独立，解码器解码新的GOP时需要之前的帧来解码后面的帧，GOP的存在也可以实现在视频中更快地定位。

**编码层次由如下部分组成：**

- 序列（Sequence）
- 图像组（Group of Pictures，GOP）
- 图像（Picture）
- 条带（Slice）
- 宏块（Macroblock，MB）
- 块(Block)

##### 编码帧的分类

1.  I帧即Intra-coded picture（帧内编码图像帧），是自带全部信息的独立帧，是最完整的画面（占用的空间最大），无需参考其它图像便可独立进行解码。视频序列中的第一个帧，始终都是 I 帧。  不参考其他图像帧，只利用本帧的信息进行编码。关键帧，采用帧内压缩技术，IDR属于I帧。一般为GOP中第一帧。
2. P帧即Predictive-codedPicture（预测编码图像帧），利用之前的I帧或P帧，采用运动预测的方式进行帧间预测编码。前面帧解码成功后再解，向前参考帧，帧间压缩技术，“帧间预测编码帧”，需要参考前面的 I 帧和 / 或 P 帧的不同部分，才能进行编码。P 帧对前面的 P 和 I 参考帧有依赖性。但是，P 帧压缩率比较高，占用的空间较小。
3.  B帧即Bidirectionallypredicted picture（双向预测编码图像帧)，提供最高的压缩比，它既需要之前的图像帧(I帧或P帧)，也需要后来的图像帧(P帧)，采用运动预测的方式进行帧间双向预测编码。前后参考帧，帧间压缩技术。“双向预测编码帧”，以前帧后帧作为参考帧。不仅参考前面，还参考后面的帧，所以，它的压缩率最高，可以达到 200:1。不过，因为依赖后面的帧，所以不适合实时传输（例如视频会议）。

##### IDR帧和I帧关系

##### 帧与分组的关系

#### H264中的宏块

宏块是编码处理的基本单元，通常宏块大小为16x16个像素。一个编码图像首先要划分成多个块（4x4 像素）才能进行处理，显然宏块应该由整数个块组成。宏块分为I、P、B宏块：I宏块（帧内预测宏块）只能利用当前片中已解码的像素作为参考进行帧内预测；P宏块（帧间预测宏块）可以利用前面已解码的图像作为参考图像进行帧内预测；B宏块（帧间双向预测宏块）则是利用前后向的参考图像进行帧内预测。

#### 帧内压缩技术



