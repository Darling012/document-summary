# 微服务日志

#### 要做什么：
1. [日志格式设计](#日志格式)
2. [怎么记录日志](#记录)
3. [日志配置](#日志配置)
4. [能够过滤出一次请求的全链路调用日志](#全链路)
5. [日志统一展示及分析](#ELKB)
6. 异步打印


## 分类
1. 系统初始化
2. 关键业务节点
3. [异常](异常.md)
4. 第三方交互

## 系统日志
为开发排查问题提供依据，一般记录在日志文件中。

##### 格式：
1. 时间|pid|日志级别|应用名称|调用链标志|当前span标识|用户标识|业务标识|线程名称|当前类全路径|日志消息体
```
   %d{${LOG_DATEFORMAT_PATTERN:-yyyy-MM-dd HH:mm:ss.SSS}}|${PID:- }|%level|${LOG_LEVEL_PATTERN:-%5p}|%t|%-40.40logger{39}: %msg%n
```
2. console彩色日志
 ```
"${CONSOLE_LOG_PATTERN:-%clr(%d{yyyy-MM-dd HH:mm:ss.SSS}){faint} %clr(${LOG_LEVEL_PATTERN:-%5p}) %clr(${PID:- }){magenta} %clr[%X{ctxLogId}] %clr(---){faint} %clr([%t]){faint} %clr(%-40.40logger{39}){cyan} %clr(:){faint} %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}}"
 ```
##### 记录方式
1. slf4j
   1. [logback](#logback配置)
      1. 
      2. [异步配置](https://blog.csdn.net/weixin_30598353/article/details/114431381)
   2. log4j2
      1. 提供了Supplier + Lambda 惰性打印：logger.debug("入参报文：{}",() -> JSON.toJSONString(pojo));
      2. [Log4j2异步](https://juejin.cn/post/6945753017878577165)
2. https://github.com/zalando/logbook
##### 中间件
如[Nginx](Nginx.md)、keepalive
1. 中间件日志格式自定义
2. 采集日志中间件处理
##### 存放
1. 本地
2. 日志中间件
##### refrence
1. [西格玛的博客正确的打日志姿势](http://lrwinx.github.io/2018/01/25/%E6%AD%A3%E7%A1%AE%E7%9A%84%E6%89%93%E6%97%A5%E5%BF%97%E5%A7%BF%E5%8A%BF/)

## 操作日志：
给用户看的系统操作日志，一般入库后展示前台。
##### 格式：
##### 记录方式
1. event事件异步入库
2. cancle
   1. [如何优雅地记录操作日志](https://tech.meituan.com/2021/09/16/operational-logbook.html)


## logback配置
1. 日志配置文件： 加载的先后顺序为logback.xml -> application.properties  -> logback-spring.xml
2. 日志级别低 -> 高：TRACE < DEBUG < INFO < WARN < ERROR < FATAL；假如root日志级别为debug：
   1. 会输出DEBUG 、 INFO 、 WARN、ERROR级别日志（slf4j没有fatal）
   2. 单独配置到包的日志级别优先级高于root节点配置
   3. yaml里的配置优先级高于logback-spring.xml
##### 动态修改日志级别
1. [Nacos配置中心](Nacos配置中心.md) 直接改
2. [SpringBoot动态修改日志级别](https://juejin.cn/post/6912439889841635335) 
3. [利用Arthas修改](https://mp.weixin.qq.com/s/b4yYZlYMdpUaT_1AsTkB_Q) 

## 全链路
### mdc
底层采用**ThreadLocal**作为数据结构，所以要解决父子线程传参问题
1. 跨线程　　TaskDecorator
2. 跨jvm 　　http调用拦截器
3. [MDC + 微服务请求链路追踪spring cloud sleuth](https://blog.csdn.net/lujia_loney/article/details/91417898)  关于子线程继承父线程mdc描述错误([Sleuth+MDC](https://segmentfault.com/a/1190000041480530)中说早期版本采用threadLocal，中间采用InheritableThreadLocal，后又因性能改为threadLocal。[ThreadLocal、InheritableThreadLocal、TransmittableThreadLocal三者区别](https://www.jianshu.com/p/a3134d70acf7))
4. [SpringBoot+MDC实现全链路调用日志跟踪](https://juejin.cn/post/6844904101483020295  )
5. [Improved Java Logging with Mapped Diagnostic Context (MDC)](https://www.baeldung.com/mdc-in-log4j-2-logback)

### Spring Cloud Sleuth
1. **springboot**
    springboot-summary项目 单独引入后，与实现AsyncConfigurer的自定义类起冲突，解决是不实现AsyncConfigurer，但其提供的用于@async 注释的 void 方法 捕获异常的方法就没有了。暂时先不解决。估计是版本冲突。（ps:不是版本问题，[Sleuth+MDC](https://segmentfault.com/a/1190000041480530)中说sleuth 会代理@async所使用线程池，也给出了自定义线程池传递方案）
```yaml
<!--        <dependency>-->
<!--            <groupId>org.springframework.cloud</groupId>-->
<!--            <artifactId>spring-cloud-starter-sleuth</artifactId>-->
<!--            <version>3.1.0</version>-->
<!--        </dependency>-->
```
2. **spring cloud**
 ai-video项目引入后，出现取不到tracId、spanId现象，经排查为源码
```java
TraceEnvironmentPostProcessor#postProcessEnvironment
# 注意service.name嵌套，不了解这种写法。
map.put("logging.pattern.level", "%5p [${spring.zipkin.service.name:"
      + "${spring.application.name:}},%X{X-B3-TraceId:-},%X{X-B3-SpanId:-},%X{X-Span-Export:-}]");
```
在yml中复写为
```yaml
logging:
  pattern:
    level: '%5p [${spring.application.name:},%X{traceId:-},%X{spanId:-},%X{X-Span-Export:-}]'
```
猜测为cloud与boot小版本对应问题导致。
3. 异常
   在restful返回体中放入traceId方便排查错误情况。
   1. [自定义异常打印工具类](异常.md#自定义ExceptionUtil)
   2. [commons.lang3.exception.ExceptionUtils](异常.md#ommons%20lang3%20exception%20ExceptionUtils)
##### refrence
1. [SpringCloud--Sleuth日志跟踪(十四)](https://www.jianshu.com/p/49960b914676)
2. [Sleuth+MDC](https://segmentfault.com/a/1190000041480530)
3. [Spring Cloud Sleuth](https://www.cnblogs.com/LQBlog/p/10396832.html)
4. [spring-cloud-gateway 集成 spring-cloud-sleuth 全链路后，traceId 不生效，无法获取 %X{traceId} 和 %X{spanId}](https://blog.csdn.net/Charlven/article/details/125175718)
5. [spring cloud sleuth 自定义traceId, spanId日志pattern](https://blog.csdn.net/Allocator/article/details/121662155)
6. [链路日志增强](https://cloud.tencent.com/developer/article/1776286)

## ELKB
##### 问题：
1. 怎么分片
##### ELK中各个服务的作用
- [Elasticsearch](https://blog.csdn.net/laoyang360/article/details/79293493): 用于存储收集到的日志信息；
- Logstash:用于收集日志，应用整合了Logstash以后会把日志发送给Logstash,Logstash再把日志转发给Elasticsearch；
- Kibana:通过Web端的可视化界面来查看日志。
- Filebeat:本地文件的[日志数据](https://cloud.tencent.com/solution/cloudlog?from=10680)采集器，可监控日志目录或特定日志文件（tail file），并将它们转发给Elasticsearch或Logstatsh进行索引、kafka等
- Rsyslog:
#### 部署
```Bash
mkdir -p /data/elk/{elasticsearch/data,logstash}     #新建目录
```
54服务器路径 /usr/local/devops/elk/docker-compose.yaml

```yaml
version: '3'
services:
  elasticsearch:
    image: elasticsearch:7.7.0  #镜像
    container_name: elk_elasticsearch  #定义容器名称
    restart: always  #开机启动，失败也会一直重启
    environment:
      - "cluster.name=elasticsearch" #设置集群名称为elasticsearch
      - "discovery.type=single-node" #以单一节点模式启动
      - "ES_JAVA_OPTS=-Xms512m -Xmx1024m" #设置使用jvm内存大小
    volumes:
      - /data/elk/elasticsearch/plugins:/usr/share/elasticsearch/plugins #插件文件挂载
      - /data/elk/elasticsearch/data:/usr/share/elasticsearch/data #数据文件挂载
    ports:
      - 9200:9200
  kibana:
    image: kibana:7.7.0
    container_name: elk_kibana
    restart: always
    depends_on:
      - elasticsearch #kibana在elasticsearch启动之后再启动
    links:
      - elasticsearch:es #可以用es这个域名访问elasticsearch服务
    environment:
      - ELASTICSEARCH_URL=http://elasticsearch:9200 #设置访问elasticsearch的地址
    ports:
      - 5601:5601
  logstash:
    image: logstash:7.7.0
    container_name: elk_logstash
    restart: always
    volumes:
      - /data/elk/logstash/logstash-springboot.conf:/usr/share/logstash/pipeline/logstash.conf #挂载logstash的配置文件
    depends_on:
      - elasticsearch #kibana在elasticsearch启动之后再启动
    links:
      - elasticsearch:es #可以用es这个域名访问elasticsearch服务
    ports:
      - 4560:4560
```
授权目录
cd /data/elk
chmod 777 elasticsearch/data
##### logstash.conf
新建/data/elk/logstash/logstash-springboot.conf文件，新增以下内容
```java
input {
  tcp{
      mode => "server"
      host => "0.0.0.0"
      port => 4560
      codec => json_lines
     }
}
output {
   if [SERVICE_NAME] == "spring-boot-summary"{
    elasticsearch {
      hosts => "es:9200"
      index => "spring-boot-summary-%{+YYYY.MM.dd}"
    }
   }
  if [service] == "edge-service-media"{
    elasticsearch {
      hosts => "es:9200"
      index => "edge-service-media-%{+YYYY.MM.dd}"
    }
   }
 if [service] == "service-exam"{
    elasticsearch {
      hosts => "es:9200"
      index => "service-exam-%{+YYYY.MM.dd}"
    }
   }
 if [service] == "service-teach"{
    elasticsearch {
      hosts => "es:9200"
      index => "service-teach-%{+YYYY.MM.dd}"
    }
   }
  if [service] == "edge-service-student-iot"{
    elasticsearch {
      hosts => "es:9200"
      index => "edge-service-student-iot-%{+YYYY.MM.dd}"
    }
   }
  if [project] == "ai-video-angang-baozhuang"{
    elasticsearch {
      hosts => "es:9200"
      index => "ai-video-angang-baozhuang-%{+YYYY.MM.dd}"
    }
   }
}
```
##### 安装，运行ELK
```Bash
docker-compose up -d
docker ps
```
##### 汉化kibana
```Bash
docker exec -it elk_kibana /bin/bash -c "echo "i18n.locale: zh-CN" >> /opt/kibana/config/kibana.yml"
docker restart elk_kibana 
```
##### logstash 安装json_lines 格式插件
```Bash
# 进入logstash容器
docker exec -it elk_logstash /bin/bash
# 进入bin目录
cd /bin/
# 安装插件
logstash-plugin install logstash-codec-json_lines
# 退出容器
exit
# 重启logstash服务
docker restart elk_logstash
```
##### filebeat
##### spring集成
```xml
<!--        输出到logstash-->
<dependency>
    <groupId>net.logstash.logback</groupId>
    <artifactId>logstash-logback-encoder</artifactId>
    <version>4.11</version>
</dependency>
```
logback-spring.xml
```xml
<appender name="LOGSTASH" class="net.logstash.logback.appender.LogstashTcpSocketAppender">
    <!--可以访问的logstash日志收集端口-->
    <destination>${LOG_STASH_HOST}:${LOG_STASH_PORT}</destination>
    <encoder charset="UTF-8" class="net.logstash.logback.encoder.LogstashEncoder"/>
    <encoder class="net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder">
        <providers>
            <timestamp>
                <timeZone>Asia/Shanghai</timeZone>
            </timestamp>
            <pattern>
                <pattern>
                    {
                    "SERVICE_NAME":"${SERVICE_NAME}",
                    "traceid":"%X{traceid}",
                    "ip": "%X{ip}",
                    "server_name": "%X{server_name}",
                    "level": "%level",
                    "trace": "%X{X-B3-TraceId:-}",
                    "span": "%X{X-B3-SpanId:-}",
                    "parent": "%X{X-B3-ParentSpanId:-}",
                    "thread": "%thread",
                    "class": "%logger{40} - %M:%L",
                    "message": "%message",
                    "stack_trace": "%exception{10}"
                    }
                </pattern>
            </pattern>
        </providers>
    </encoder>
</appender>
```


[Logstash、Fluentd、Fluent Bit 还是 Vector？](https://mp.weixin.qq.com/s/yZh3LDmMW7EQurj0W-9wGA)

