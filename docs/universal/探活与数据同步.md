# 探活与数据同步
## 背景
k12 考试模块需要调用算法模块，在算法模块只提供算法接口的条件下，存在多个计算节点时，就需要先判断节点是否可用再分配任务，也就是需要对节点进行探活。想到两种探活方式：
1. 下发任务时根据返回状态判断节点状态
2. 心跳周期探活

是选用其中一个还是两个配合做了思考：
1. 只用节点返回状态判断
	1. 任务进行中节点卡死情况，这就需要周期性进行探死
		1. 假如存在周期扫描 AI 打分任务表的定时任务，可根据某个任务是否超期，再次调用下发任务接口，打破卡死状态。
2. 只用心跳
	1. 周期内失活，任务恰好下发

这个场景类似[注册中心](注册中心.md)。类似[配置中心](配置中心.md)的场景为全站仪中的数据同步：
1. 增量同步，提供了单条数据同步接口，当第三方发生变化时立马调用。
2. 全量同步，为了防止单条数据接口调用失败，周期性调用全量同步接口。
其中
1.  单个周期发生数据变动情况。要想周期调用拥有时效性，就得减少间隔，占用更多的服务器资源。好处与上游模块解耦。
2.  消息驱动，单次调用不通，超过最大重试次数，人工介入前，周期调用可以进行补偿

###### 是否引入mq
1. 队列与数据入库怎么选？
	1. 数据入库+定时任务+重试
	2. 队列保证百分百投递也挺复杂。对比着看入库就更合适了。
2. 进程内队列与中间件队列选哪个？
	1. 等同缓存，考虑跨进程（别的服务读不到）和持久化问题。
###### mq 优势有无替代方案
1. 异步
	1. 可以通过 rpc 接口再次回调实现
2. 解耦
	1. 不再主动调用其他模块，通过入库+定时扫描解决。需通知多个模块时，消息订阅退化成了观察者。

## 问题
1. 单个事件消息驱动与周期性同步更细分的试用场景是什么？
	1. 轮询与事件驱动模型
2. 注册中心的探活与配置中心的数据同步具体方案是什么？
3. 前后端的实时数据同步，其实可以看做两个系统的数据同步
	1. comet4j 的演变及相关技术点
	2. [WEB即时通讯](WEB即时通讯.md)
4. 两个系统的[数据同步](大数据量同步.md)其实就是分布式数据一致性问题，通用解决方案有哪些？
5. 总结这几个问题共性，什么场景什么特性解决了什么问题。
6. 关联关键词
	1. 消息驱动
	2. 事件驱动
	3. 轮询方式
	4. 早期了解的 comet4j，前后端实时通信

## 思考
### 如何获取数据实时变化？
A 服务产生新数据，B 服务立即能同步
1. B 不断轮询A
2. 数据驱动,[异步](异步.md)
	1. A 产生数据后 RPC 调用 B 通知，~~类似 观察者，B 一直观察 A~~   应该是类似回调
	2. A 产生数据后发送到 MQ，B 订阅。类似发布订阅

前端如何实时获取后端数据
1. 轮询
2. 基于 http 长连接的长轮询
3. websocket、sse

其中，引申到 http 与 tcp 相关
1. http 短连接就是一次 tcp 连接中，一次 http 请求响应
2. http 长连接是一次 tcp 连接中多次 http 请求响应
3. 短轮询就是立马响应，长轮询就是服务端 hold 住，有消息再响应
4. tcp 本身没有长短之分，短连接就是一次读写后关闭，长连接就是复用连接
5. http 的 keep-alive 是用于表明建立的是 http 长连接
6. [TCP 的 Keepalive](TCP.md#KeepAlive) 是在两端一直没有数据交互后，自动发送心跳包保活

==tcp 的 Keepalive 的心跳包就关联到保活==，没想到从背景里分析出问题，在这里两个问题有了交集。

看  [websocket](websocket.md#^pf6ii8) 时，串起了几个应用场景。
###### 总结一下
无论是前后端数据交互还是不同微服务，也不管是获取数据还是判断是否可用，都是两个端进行通信，所以问题就是通信方式的区分，同步和[[异步]]，同步就是轮询，不断的调用，无论是长轮询短轮询，基于长连接还是短连接，也就是肯定存在无效的调用。异步呢就是有数据时被动接收数据，不需要主动的调用，也就是利用[回调](回调、观察者、事件监听、发布订阅.md)、[[事件驱动]]。

[用了这么久配置中心，还不知道长轮询是什么？ - 徐靖峰|个人博客](https://www.cnkirito.moe/nacos-and-longpolling/)
1. 数据交互模式
	1. Push（推模式）和 Pull（拉模式）。
### 开源软件中怎么实现的
1. Nacos 使用了`AsyncContext`
2. Apollo 使用了`DeferredResult`


## reference
#### 轮询与事件驱动
[软件设计杂谈——事件驱动 · Joey's Tech Notes & Blogs](https://code2life.top/2020/08/12/0054-polling-to-event-driven/)
1. 如何获取数据实时变化？
	1. 可能是异步情况的唯一手段：while (true) 一把梭，轮询变化
2. 前端如何获取数据变化
	1. 用户输入或 DOM 实时变化
		1. 浏览器提供的 EventListener，底层依托于浏览器 Event Loop 轮询任务队列
		2. [JavaScript异步机制详解 - 掘金](https://juejin.cn/post/6844903556084924423)
	2. 后台数据变化
		1. 长轮询，将事件放入任务队列
		2. websocket, 长轮询用于一直保持 HTTP 连接的无限循环被干掉了，但 WebSocket 的 I/O 事件仍然是由 Event Loop 拿过去的
	3. 总结
		1. 无法避免总有一个while true
3. 后端如何获取数据的变化
	1. A 服务改了数据 X，如何通知到依赖数据 X 的 B 服务？
		1. 低效（大量请求无用）的轮询，B 不断轮询 A 变化了没有
		2. 好一点的一般有两个办法，微服务中采用
			1. A 直接告诉 B，A 通过同步的 RPC 或 HTTP 调用B
				1. 适合 A 服务强依赖 B 服务并且一定要同步调用情况，可视作 Subject 通知 Observer 的**观察者模式**
			2. A 把消息放出去，B 通过同步或异步的消息队列去订阅。
				1. 适合当 A 服务不需要强依赖 B 时，引入消息队列干掉 A、B 之间的耦合，引入了中介的 Broker 可以视作**发布订阅模式**
4. 藏在 BIO、NIO、I/O 多路复用中的轮询
	1. 大意是 NIO 里轮询 selector 中是否有新事件
5. 从轮询到事件驱动
	1. 通过前后端的例子发现最优解都是 
	2. **事件队列的轮询藏在底层，把事件驱动模型提供给应用层**，以此达到高效地实时通知数据变化的效果。
	3. 底层轮询事件消息队列的实现，某种意义上充当了发布订阅模式中**Broker**的角色。
6.  crud 本质
	1. Create Update Delete 这三个动作抽象的是**事物从生到死**的整个生命周期
	2. Read 代表对事物**当前状态的观测**，观测的结果就是软件的业务价值
		1. 更高阶 read 就是对结果数据进行大数据或机器学习
	3. crud 模型是静态视角
		1. 每个动作相对独立，没有体现当 cud 发生时，**对其他事物产生什么样的影响**
		2. 避免耦合，但模拟的现实事物又彼此关联，当**事物互相影响的复杂度大于事物自身生命周期维护的复杂度**时，CRUD 就体现出其局限性了。我们用各种 RPC 调用来互相通知产生的影响、或用消息队列到处传播自身的变化，最终系统变得复杂。
7.  cqrs 模式带来了什么
		1. 命令与查询分离
			1. **在单独的查询组件读取当前状态的数据视图**
			2. 写操作与读操作所对应的数据库是**异构**的：**写进去的是命令对应的事件；读出来的是经历 N 个事件之后，数据的当前状态视图**。
8. cqrs+Event Sourcing (事件溯源)
	1. 系统**并不直接写入、更新数据本身，而是不停地追加事件**。
	2. ......... 需要储备知识再了解 #todo
9. 总结
	1. 事件驱动模式底层的核心机制——轮询事件队列


比较底层的
[万字长文：手把手教你实现一套高效的IM长连接自适应心跳保活机制-IM开发/专项技术区 - 即时通讯开发者社区!](http://www.52im.net/thread-3908-1-1.html)
[聊聊 TCP 长连接和心跳那些事](https://www.cnkirito.moe/tcp-talk/)



[如何将计算机网络、操作系统、数据结构与算法、计算组成融会贯通？ | 小林coding](https://www.xiaolincoding.com/cs_learn/feel_cs.html#%E6%A1%88%E4%BE%8B%E9%9C%80%E6%B1%82)
如何设计一个**高性能的单机管理主机的心跳服务**？
==两个关注点==
1. 发现宕机的主机
2. 发现上线的主机
==三个维度设计==
1. 宕机判断算法的设计
	1. 心跳包用什么DS存储？
	2. 心跳就是主机上报时间。有时序关系，所以用双向链表构成先入先出的队列。
	3. 这样新的IP可以直接插入队尾，超时的直接从队头删除。复杂度都是O(1)。
	4. 那么更新呢？要先从队列中查找到，删除后，再插入到队尾。
	5. 双向链表的查询复杂度是O (N)，查询效率最好的数据结构就是「哈希表」了，时间复杂度只有 O (1)。
	6. 所以引入哈希表，key是主机IP，value为主机在双向链表中的节点
	7. 当收到新的心跳包
		1. 如果不存在哈希表里，说明是新主机上线，先将其插入到双向链表的尾部，然后将该主机的 IP 作为 Key，主机在双向链表的节点作为 Value 插入到哈希表。
		2. 如果存在哈希表里，说明主机已经上线过，先通过查询哈希表，找到该主机在双向链表里旧的心跳包的节点，然后就可以通过该节点将其从双向链表中删除，最后将新的心跳包插入到双向链表的队尾，同时更新哈希表。
	8. 可以看到，上面这些操作全都是 O (1)，不管集群规模多大，时间复杂度都不会增加，但是代价就是内存占用会越多，这个就是以空间换时间的方式。
	9. 为什么要用双向链表？
		1. 因为删除中间节点方便。
	10. 删除了双向链表也要更新哈希表，怎么找到哈希表的key
		1. 双向链表节点要存储IP+主机信息。
		2. 这样就可以通过IP在哈希表中找到要删除的节点了。
	11. 上面这个算法就是**类 LRU 算法**，用于**淘汰最近最久使用的元素**的场景，该算法应用范围很广的，操作系统、Redis、MySQL 都有使用该算法。
2. 高并发架构的设计
	1. 选择单线程、多线程还是多进程？
		1. 单线程只能用一个cpu算力不足
		2. 多进程内存不共享通信麻烦
	2. 多线程体现在「分发线程是多线程和工作线程是多线程」
		1. 多路复用，epoll
		2. 负载均衡，心跳包均匀分发到不同的工作线程上处理。哈希函数，不同的工作线程互不干扰，不用加锁。
			1. 工作线程多余分发线程，给每个工作线程创建缓冲队列
			2. 缓冲队列会被分发线程和工作线程同时操作，所以要加锁，为了避免线程获取锁失而主动放弃 CPU，选择自旋锁。因为自旋锁在获取锁失败后，CPU 还在执行该线程，只不过 CPU 在空转，效率比互斥锁高。
		3. 线程绑定CPU
3. 传输层协议的选择
	1. 选择TCP还是UDP看心跳包长度
		1. 小于MTU，选UDP
		2. 大于 [MTU](https://zh.wikipedia.org/zh-cn/%E6%9C%80%E5%A4%A7%E4%BC%A0%E8%BE%93%E5%8D%95%E5%85%83)，选TCP