# 大数据量同步

##### 背景：
需同步第三方数据场景，不局限于两个后端服务，比如前端请求后端大量数据。
大概可以分为三块：
1. 在网络中传输
2. 被调用方准备数据
4. 调用方持久化到数据库
##### 问题
1. 怎么高效将数据获取？
   1. 如何切分请求参数，进行并发请求
2. 怎么高效将数据持久化？
   1. 单个数据库连接如何存储更多的数据？
   2. 怎么并发存贮？
3. 并发条件下如何保证数据业务正确性？
   1. 数据前后依赖如何保证顺序
   2. 如何保证所有数据都同步
4. 远端直接导出数据成文件，调用端 load 文件是不是更快？
	1. [一个](https://blog.csdn.net/linzhiqiang0316/article/details/100532267) [相关](https://linzhiqiang.blog.csdn.net/article/details/113772783) [例子](https://linzhiqiang.blog.csdn.net/article/details/129912733)
	2. 像 redis、mysql 等数据库的同步方案是不是都是文件？
5. 两端数据一致性
## 优化查询
1. 直接查询
	1. mysql 建索引
	2. 从 clickhouse、mongo 等 nosql 数据库查
2. 冗余数据
	1. 建立中间查询表，定时更新数据
	2. 业务强相关的查出来放缓存，预防真的需要查
## RPC
1. http
	1. ajax、fegin
	2. grpc
2. 非 http
	1. ws
	2. mq

##### 异步RPC


### http

#### 前后端
思路上一个是多建连接并行请求，但 [http1.1 受限制](WEB即时通讯.md#浏览器限制同源%20HTTP%201%20x%20连接并发个数的问题)，可以利用 [http2.0](http.md#http%202%200)。服务端怎么优化呢？http 2.0 是同一个 tcp 多个请求，~~是建立多个 tcp？然后每个 tcp 上并行多个请求？~~不允许建立多个
协程在这里相比线程的优势可能是能尽量跑满时间片，节省的时间应该微乎其微。
[ http请求大数据量耗时较长如何解决](https://segmentfault.com/q/1010000040055697)

#### 微服务
7. [Okhttp的线程池和高并发](https://juejin.cn/post/6949527136088621070)
8. [为SpringBoot接口适配Gzip压缩数据请求加快超大Json对象的传输速度](https://blog.csdn.net/weixin_43441509/article/details/123816603)
9. [http请求大数据量耗时较长如何解决](https://segmentfault.com/q/1010000040055697)
10. [Java多线程大批量同步数据（分页）](https://blog.csdn.net/u011019141/article/details/101521565)
11. [Java 中并发请求多个接口怎样才能效率最高呢？](https://www.zhihu.com/question/382668099)

#### 请求合并
比如查询 id 为 1-10 数据，需 10 次 rpc+10 次读取数据库，可以提供一个批量处理的接口，然后结合 HystrixCollapser，就可以通过调用普通单个接口 10 次转为第 10 次调用批量接口。就成了 1 次 rpc+读取数据库。 还有类似大文件分片下载、大数据分片入库。

[为什么要合并HTTP请求？ - 简书](https://www.jianshu.com/p/9a3f0e84c2b0)

[页面请求的拆 Or 不拆 - 掘金](https://juejin.cn/post/7081153054531125262)
##### http 2

##### hystrix
[什么是高并发下的请求合并？](https://heapdump.cn/article/3356787)
[基于 request collapser 请求合并技术进一步优化批量查询](https://zq99299.github.io/note-book/cache-pdp/hystrix/100.html#%E8%AF%B7%E6%B1%82%E5%90%88%E5%B9%B6%E5%8E%9F%E7%90%86-%E5%AE%98%E7%BD%91)
##### mybatis plus
[MybatisPlus请求合并拆分在并发场景中应用](https://www.altitude.xin/blog/home/#/chapter/ad38552c70ef71f71ef92e7f50886739)
对于一定时间区间内的所有请求，合并成一条请求处理。
##### 自定义
[ Java代码优化-请求合并与分而治之](https://mp.weixin.qq.com/s/7aHQnDckODB0OWPcWGfinA)
[请求合并哪家强](https://zhenbianshu.github.io/2018/07/multi_request_collapse.html)

##### 并发请求
CompletableFuture

##### go
偶然看到，也是合并，但是只执行一次
[singleflight 合并事件推送](https://mp.weixin.qq.com/s/PFojA2DWJF7ry9Rdu8znyA)
### grpc
[grpc](RPC.md#grpc)
## 持久化

### orm
要想插入速度快，从两个方向考虑
1. 执行的sql要尽可能包含更多的数据
2. 并发执行
要保证数据完整性，要加事务。
#### 单条sql
单条sql包含更多数据采用insert valuse 样语句，一条sql包含多条记录。参考[MyBatis-Plus批量操作](MyBatis-Plus批量操作.md)。
#### 并发执行
并发执行思路是将数据分割后，每一块数据开启一个线程执行入库操作。具体为要有个一全局变量flag默认为false不可以提交。主线程分割n份后交由n个子线程执行，主线程mainCountDownLatch.await阻塞。子线程手动开启事务，执行sql后若发生异常则将flag更新为false，若没有异常则子线程则childCountDownLatch.await阻塞，mainCountDownLatch.countDown减一。等所有子线程完成也就唤醒了mainCountDownLatch.await，然后再执行childCountDownLatch.countDown唤醒子线程，子线程判断flag来执行commit还是rollback。再优化可以区分每个子线程执行结果，出现异常立即回滚。提供个List收集子线程结果，通过list结果集更新flag。
##### 问题
[要我说，多线程事务它必须就是个伪命题！](https://segmentfault.com/a/1190000037770701)
1. 部分线程提交成功，还有部分没有，但系统挂了。
##### 多线程、数据库事务、数据库连接之间的关系
[多线程与数据库事务以及数据库连接之间的关系](https://cloud.tencent.com/developer/article/1861190)
1. 同一个controller（单例多线程）的方法，当发生并发时情况
	1. 事务基于数据库连接，单线程可在同一个数据库连接上执行多个事务。
	2. 多线程获取不同连接执行各自的事务，在提交时靠隔离级别决定是否互相影响。
	3. spring用threadLocal保证同一个线程获取同一个数据库连接。
2. 多线程获取不同的数据库连接，开启各自的事务，事务之间的关系就靠隔离性决定。
3. 多线程获取相同的数据库连接，就会产生事务冲突，因为隔离性基于不同的数据库连接，所以避免不了这种情况
4. spring通过threadLocal保证同一个线程的多次操作是同一个connection。以此来保证同一个事务。

当一个请求，存在写两处及以上，就必然存在数据不一致风险。

[Spring在多线程环境下如何确保事务一致性\_多线程如何保证事务\_Binary Oracle的博客-CSDN博客](https://blog.csdn.net/m0_53157173/article/details/127423286)
1. 使用 `CompletableFuture` 将原本串行的三个删除操作改为前两个并行，等第三个执行完再提交事务
2. 
##### 代码参考
1.  [项目开发之Spring多线程事务如何一起提交一起回滚(附代码)，并发处理批量数据，实现多线程事务回滚，事务补偿](https://blog.csdn.net/Seven71111/article/details/109727147)
2. [自定义注解实现springboot 多线程事务(基于@Async注解的多线程)\_springboot多线程注解\_清汤面不加盐的博客-CSDN博客](https://blog.csdn.net/weixin_69672118/article/details/127675808)
3. 

##### 插入方式对比
[JAVA向Mysql插入亿级别数据---测评](https://blog.csdn.net/q6834850/article/details/73726707)
	1.  Mybatis 轻量级框架插入 , mybatis在我这次实验被黑的可惨了，哈哈。实际开启事务以后，差距不会这么大（差距10倍）。
	2. JDBC直接处理，在本次实验，开启事务和关闭事务，耗时差距5倍左右，并且这个倍数会随着数据量的增大而增大。因为在未开启事务时，更新10000条数据，就得访问数据库10000次。导致每次操作都需要操作一次数据库。
	3. JDBC批处理，在本次实验，开启事务与关闭事务，耗时差距很微小（后面会增加测试，加大这个数值的差距）。但是能够看到开启事务以后，速度还是有提升。

[Java多线程数据库事务提交控制](https://blog.csdn.net/qq273766764/article/details/119972911)
1. 循环操作的代码
2. 使用手动事务的操作代码
3. 尝试多线程进行数据修改
4. 基于两个CountDownLatch控制多线程事务提交
5. 基于TransactionStatus集合来控制多线程事务提交
6. 使用union连接多个select实现批量update

##### 大事务还是小事务
事务跟磁盘刷新的关系？
回滚是哪个日志提供的保证？
什么时候从缓存刷新到磁盘？
假如事务太大，比如一直往缓存里写，commit前缓存爆了怎么办？

### load  data in file
mysql import 调用了 load  data in file 语句来实现数据导入,前者提供了一种简便的命令行接口,后者是具体导入实现的 SQL 语句。

用法
[1](https://cloud.tencent.com/developer/article/1710165)，[2](https://blog.csdn.net/longzhoufeng/article/details/112377942)，[3](https://blog.csdn.net/u012815136/article/details/88953289)，[4](https://leokongwq.github.io/2015/06/11/HowMysqlLoadDataWorks.html)，[5](https://segmentfault.com/a/1190000039713242)，[6](https://www.cnblogs.com/applelife/p/10516326.html)

[MYSQL: 如何快速导入上亿规模大量数据 | RESTKHZ](https://blog.restkhz.com/post/quickly-insert-data-into-mysql)
1. 最快的导入方法：使用LOAD DATA INFILE
2. 回归老问题：插入速度优化原理
3. 当我们插入数据的时候，什么消耗时间？如果按重要程度排序的话。
	1. 事务最后一步把数据同步到硬盘
	2. 键的更新，索引越大耗时越长
	3. 检查外键，如果有的话
	4. 在存储引擎里加新的行
	5. 把数据发给server
4. 同步到硬盘和发数据这里我就不多说了，我没有RAID也没有千兆网。这方面我不懂。
5. 所以
	1. 禁用索引。`LOAD DATA INFILE`会自动暂时禁用索引。`INSERT`导入你需要自己禁用。
	2. 禁用约束
	3. 其他可优化的参数
6. 还是用INSERT导入，如何优化？
	1. 首先还是根据之前列出的，首先临时禁用索引和外键。这两个开销很大。
	2. 扎堆放进一个事务
		1. 很多插入连续在一起，可以放进一个大的事务。可以避免频繁同步到硬盘，硬盘读写很耗时。但要注意..
	3. 一次INSERT插入多个值，占满`max_allowed_packet`


[怎样用java向MySQL中的表插入1亿条数据 - PingCode 一站式研发项目管理平台](https://docs.pingcode.com/ask/33790.html)
1. 使用MySQL的存储过程
2. 使用LOAD DATA INFILE
3. 使用Java的JDBC调用addBatch()和executeBatch()方法
#### 数据错误怎么办？
导入的时候是有事务的。
感觉应该在导出file时控制。或者经过一遍代码验证。
## reference
1. [亿级别大表拆分 —— 记一次分表工作的心路历程](https://juejin.cn/post/7078228053700116493)